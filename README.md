# Sem-NeuS: Semantically-Guided High-Fidelity Neural Surface Reconstruction

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Framework: PyTorch](https://img.shields.io/badge/Framework-PyTorch-orange.svg)](https://pytorch.org/)
[![Conference: ICPR 2026](https://img.shields.io/badge/Conference-ICPR_2026-blue.svg)](https://icpr2026.org/)

This repository contains the official implementation of **Sem-NeuS**, a framework for high-fidelity 3D reconstruction that integrates **Semantic-Guided Geometry Distillation** with a hierarchical SDF architecture. By distilling features from Vision Foundation Models (DINOv3) into 3D geometry, our method resolves ambiguities in textureless and thin structures (e.g., insect limbs) without using semantic features as direct input.

<p align="center">
  <img src="assets/teaser_final_polished.png" alt="Sem-NeuS Teaser" width="100%">
</p>

## üõ†Ô∏è Installation

### 1. Clone the repository
```bash
git clone https://github.com/yourusername/Sem-NeuS.git
cd Sem-NeuS
2. Environment Setup
We recommend using Anaconda to manage dependencies.
code
Bash
conda create -n semneus python=3.9
conda activate semneus
3. Install Dependencies
Install the required Python packages:
code
Bash
pip install -r requirements.txt
ü¶ï DINOv3 Model Setup
Our framework relies on a pre-trained DINOv3 model (ViT-L/16) to provide semantic guidance. You must download the weights before training.
Download the weights:
Download the dinov3_vitl16.pth checkpoint.
code
Bash
# Example (Update URL if hosting your own weight file, or download manually)
wget https://dl.fbaipublicfiles.com/dinov3/dinov3_vitl16.pth
Place the file:
Move the .pth file to the root directory of this repository. Your folder structure should look like this:
code
Text
Sem-NeuS/
‚îú‚îÄ‚îÄ dinov3_vitl16.pth        <-- Place here
‚îú‚îÄ‚îÄ exp_runner_high.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ semantic/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...
Note: You do not need to manually extract features. The training script automatically detects if features are missing for a dataset and runs the extractor (models/semantic/preprocess.py) before training starts.
üìÇ Data Preparation
Organize your data following the standard NeuS format. For custom datasets (e.g., insects), use COLMAP to generate camera poses.
code
Text
data/
‚îî‚îÄ‚îÄ <CASE_NAME>/
    ‚îú‚îÄ‚îÄ image/               # Input RGB images
    ‚îú‚îÄ‚îÄ mask/                # (Optional) Foreground masks
    ‚îú‚îÄ‚îÄ cameras_sphere.npz   # Camera parameters (NeuS format)
    ‚îî‚îÄ‚îÄ dinov3_features/     # (Auto-generated by code)
üöÄ Usage
1. Training
To train a scene, run exp_runner_high.py. The script will automatically extract DINO features if they don't exist.
code
Bash
python exp_runner_high.py \
    --mode train \
    --conf ./confs/womask_high_dtu.conf \
    --case <CASE_NAME>
--case: The name of your scene folder inside data/ (e.g., china_statue, insect_01).
--conf: Configuration file path.
2. Mesh Extraction (Validation)
To extract the mesh from a trained model using Marching Cubes:
code
Bash
python exp_runner_high.py \
    --mode validate_mesh \
    --conf ./confs/womask_high_dtu.conf \
    --case <CASE_NAME> \
    --is_continue \
    --mesh_resolution 1024
The output mesh will be saved in exp/<CASE_NAME>/meshes/.
3. Novel View Synthesis
To render novel views (interpolation) between two cameras:
code
Bash
python exp_runner_high.py \
    --mode interpolate_0_10 \
    --conf ./confs/womask_high_dtu.conf \
    --case <CASE_NAME> \
    --is_continue
