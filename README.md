# Sem-NeuS
Sem-NeuS: Semantically-Guided High-Fidelity Neural Surface Reconstruction via Geometry Distillation
![alt text](https://img.shields.io/badge/License-MIT-yellow.svg)

![alt text](https://img.shields.io/badge/Framework-PyTorch-orange.svg)

![alt text](https://img.shields.io/badge/Conference-ICPR_2026-blue.svg)
This repository contains the official implementation of Sem-NeuS, a framework for high-fidelity 3D reconstruction that integrates Semantic-Guided Geometry Distillation with a hierarchical SDF architecture. By distilling features from Vision Foundation Models (DINOv3) into 3D geometry, our method resolves ambiguities in textureless and thin structures (e.g., insect limbs) without using semantic features as direct input.
<p align="center">
<img src="assets/teaser_final_polished.png" alt="Sem-NeuS Teaser" width="100%">
</p>
üõ†Ô∏è Installation
1. Clone the repository
code
Bash
git clone https://github.com/yourusername/Sem-NeuS.git
cd Sem-NeuS
2. Environment Setup
We recommend using Anaconda to manage dependencies.
code
Bash
conda create -n semneus python=3.9
conda activate semneus
3. Install Dependencies
Install the required Python packages listed in requirements.txt:
code
Bash
pip install -r requirements.txt
ü¶ï DINOv3 Model Setup
Our framework relies on a pre-trained DINOv3 model (ViT-L/16) to provide semantic guidance. You must download the weights before training.
Download the weights:
Download the dinov3_vitl16.pth checkpoint.
(Note: If using the official Facebook Research release, ensure the filename matches).
code
Bash
# Example (Update URL if hosting your own weight file)
wget https://dl.fbaipublicfiles.com/dinov3/dinov3_vitl16.pth
Place the file:
Move the .pth file to the root directory of this repository:
code
Code
Sem-NeuS/
‚îú‚îÄ‚îÄ dinov3_vitl16.pth  <-- Place here
‚îú‚îÄ‚îÄ exp_runner_high.py
‚îú‚îÄ‚îÄ models/
‚îî‚îÄ‚îÄ ...
Note: You do not need to manually extract features. The training script automatically detects if features are missing for a dataset and runs the extractor (models/semantic/preprocess.py) before training starts.
üìÇ Data Preparation
Organize your data following the standard NeuS format. For custom datasets (e.g., insects), use COLMAP to generate camera poses.
code
Text
data/
‚îî‚îÄ‚îÄ <CASE_NAME>/
    ‚îú‚îÄ‚îÄ image/               # Input RGB images
    ‚îú‚îÄ‚îÄ mask/                # (Optional) Foreground masks
    ‚îú‚îÄ‚îÄ cameras_sphere.npz   # Camera parameters (NeuS format)
    ‚îî‚îÄ‚îÄ dinov3_features/     # (Auto-generated by code)
üöÄ Usage
1. Training
To train a scene, run exp_runner_high.py. The script will automatically extract DINO features if they don't exist.
code
Bash
python exp_runner_high.py \
    --mode train \
    --conf ./confs/womask_high_dtu.conf \
    --case <CASE_NAME>
--case: The name of your scene folder inside data/ (e.g., china_statue, insect_01).
--conf: Configuration file path.
2. Mesh Extraction (Validation)
To extract the mesh from a trained model using Marching Cubes:
code
Bash
python exp_runner_high.py \
    --mode validate_mesh \
    --conf ./confs/womask_high_dtu.conf \
    --case <CASE_NAME> \
    --is_continue \
    --mesh_resolution 1024
The output mesh will be saved in exp/<CASE_NAME>/meshes/.
3. Novel View Synthesis
To render novel views (interpolation):
code
Bash
python exp_runner_high.py \
    --mode interpolate_0_10 \
    --conf ./confs/womask_high_dtu.conf \
    --case <CASE_NAME> \
    --is_continue
